{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af0e74e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:47:17.460166Z",
     "start_time": "2024-07-10T12:47:17.454006Z"
    },
    "id": "af0e74e3"
   },
   "source": [
    "Saving and Sharing Models\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538848a6",
   "metadata": {
    "id": "538848a6"
   },
   "source": [
    "Author: Nathan A. Mahynski\n",
    "\n",
    "Date: 2024/07/10\n",
    "\n",
    "Description: After creating a great model, how can I (easily) save it for future use or share it with someone else?\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mahynski/pychemauth/blob/main/docs/jupyter/api/sharing_models.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1b9ac2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:56:44.410829Z",
     "start_time": "2024-07-10T13:56:44.404969Z"
    },
    "id": "1b1b9ac2"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install git+https://github.com/mahynski/pychemauth@main\n",
    "    import os\n",
    "    os.kill(os.getpid(), 9) # Automatically restart the runtime to reload libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96e772e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:56:45.289257Z",
     "start_time": "2024-07-10T13:56:44.811184Z"
    },
    "id": "b96e772e"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import pychemauth\n",
    "except:\n",
    "    raise ImportError(\"pychemauth not installed\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import watermark\n",
    "%load_ext watermark\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2acd5974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:56:46.756050Z",
     "start_time": "2024-07-10T13:56:45.291519Z"
    },
    "id": "2acd5974"
   },
   "outputs": [],
   "source": [
    "import imblearn\n",
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris as load_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pychemauth.preprocessing.scaling import CorrectedScaler\n",
    "from pychemauth.classifier.simca import DDSIMCA_Model\n",
    "from pychemauth.utils import HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b576f65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:56:46.790820Z",
     "start_time": "2024-07-10T13:56:46.758652Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b576f65",
    "outputId": "3d2ba911-3258-4f6a-c3c8-cfb542219ec2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.12\n",
      "IPython version      : 7.34.0\n",
      "\n",
      "Compiler    : GCC 11.4.0\n",
      "OS          : Linux\n",
      "Release     : 6.1.85+\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 2\n",
      "Architecture: 64bit\n",
      "\n",
      "numpy     : 1.24.3\n",
      "watermark : 2.4.3\n",
      "pychemauth: 0.0.0b4\n",
      "matplotlib: 3.7.2\n",
      "sklearn   : 1.3.0\n",
      "imblearn  : 0.11.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -t -m -v --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5696470",
   "metadata": {
    "id": "e5696470"
   },
   "source": [
    "Create a Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a1ea54",
   "metadata": {
    "id": "07a1ea54"
   },
   "source": [
    "Let's create a simple model as an example to work with.  in this case, let's build a pipeline which uses a DD-SIMCA model to model a single flower in the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1701565",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:56:46.818482Z",
     "start_time": "2024-07-10T13:56:46.792329Z"
    },
    "id": "d1701565"
   },
   "outputs": [],
   "source": [
    "X, y = load_data(return_X_y=True, as_frame=True)\n",
    "\n",
    "# Let's turn the indices into names\n",
    "names = dict(zip(np.arange(3), ['setosa', 'versicolor', 'virginica']))\n",
    "y = y.apply(lambda x: names[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a419575c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:56:46.883651Z",
     "start_time": "2024-07-10T13:56:46.820682Z"
    },
    "id": "a419575c"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X.values,\n",
    "    y.values, # Let's try to predict the salary based on the other numerical features.\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    test_size=0.2,\n",
    "    stratify=y # It is usually important to balance the test and train set so they have the same fraction of classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d6b02d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:56:47.556835Z",
     "start_time": "2024-07-10T13:56:47.511069Z"
    },
    "id": "8d6b02d1"
   },
   "outputs": [],
   "source": [
    "# Let's just model a single type of iris for this example\n",
    "chosen_class = 'setosa'\n",
    "\n",
    "X_train_dds = X_train[y_train == chosen_class]\n",
    "y_train_dds = y_train[y_train == chosen_class]\n",
    "\n",
    "X_test_dds = X_test[y_test == chosen_class]\n",
    "y_test_dds = y_test[y_test == chosen_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c3a78d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:56:48.255925Z",
     "start_time": "2024-07-10T13:56:48.211758Z"
    },
    "id": "1c3a78d7"
   },
   "outputs": [],
   "source": [
    "# Now let's build a simple pipeline\n",
    "model = imblearn.pipeline.Pipeline(\n",
    "    steps=[\n",
    "        (\"autoscaler\", CorrectedScaler( # Then, we should center and scale the data\n",
    "            with_mean=True,\n",
    "            with_std=True,\n",
    "            pareto=False\n",
    "            )\n",
    "        ),\n",
    "        (\"my_chosen_model\", DDSIMCA_Model( # Finally, we will pass the cleaned, balanced, and scaled data to the model\n",
    "            n_components=1,\n",
    "            scale_x=True\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93df6a06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:56:48.732785Z",
     "start_time": "2024-07-10T13:56:48.609881Z"
    },
    "id": "93df6a06"
   },
   "outputs": [],
   "source": [
    "_ = model.fit(X_train_dds, y_train_dds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae1020da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:56:49.107578Z",
     "start_time": "2024-07-10T13:56:49.063474Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae1020da",
    "outputId": "da5f1ea2-be51-440b-b9ef-bee54af3b887"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_dds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83a3e55c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:56:49.692524Z",
     "start_time": "2024-07-10T13:56:49.646151Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83a3e55c",
    "outputId": "7795ab25-4800-4662-b066-fa3bb54dcc37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'autoscaler': <pychemauth.preprocessing.scaling.CorrectedScaler at 0x7a7bed6be080>,\n",
       " 'my_chosen_model': DDSIMCA_Model(n_components=1)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0f55a3",
   "metadata": {
    "id": "ab0f55a3"
   },
   "source": [
    "If we just want to save the model to disk, called \"serialization\", there are a number of ways we can accomplish this.  Perhaps the simplest way is to use <a href=\"https://docs.python.org/3/library/pickle.html\">`pickle`</a> which is the preferred way to serialize Python objects.  The commands look like this:\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "\n",
    "# To save the model disk, ensure the file is opened with \"w\"rite permissions\n",
    "pickle.dump(model, file=open('my_model.pkl', 'wb'), protocol=4)\n",
    "\n",
    "# To load the model from disk, ensure the file is opened with \"r\"ead permissions\n",
    "stored_model = pickle.load(open('my_model.pkl', 'rb'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6fad6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:55:58.022823Z",
     "start_time": "2024-07-10T12:55:57.999444Z"
    },
    "id": "cd6fad6d"
   },
   "source": [
    "Hugging Face\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb19273",
   "metadata": {
    "id": "5fb19273"
   },
   "source": [
    "However, pickling is not most ideal way to store models long term since we can lose track of them and we may forget some of the details of how it works, what it was trained on, etc. if the model is renamed or transferred somewhere else.\n",
    "\n",
    "A better solution is to use a centralized hub service which can store, deploy, track, and document the model.  [Hugging Face](https://huggingface.co/) is one such service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4538d79",
   "metadata": {
    "id": "f4538d79"
   },
   "source": [
    "<h4>From the Hugging Face Hub <a href=\"https://huggingface.co/docs/hub/index\">documentation</a>:</h4>\n",
    "\n",
    "> \"The Hugging Face Hub is a platform with over 350k models, 75k datasets, and 150k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together. The Hub works as a central place where anyone can explore, experiment, collaborate, and build technology with Machine Learning.\n",
    ">\n",
    "> <h5>What can you find on the Hub?</h5>\n",
    ">\n",
    "> The Hugging Face Hub hosts Git-based repositories, which are version-controlled buckets that can contain all your files. ðŸ’¾\n",
    ">\n",
    "> On it, youâ€™ll be able to upload and discoverâ€¦\n",
    ">\n",
    "> * Models, hosting the latest state-of-the-art models for NLP, vision, and audio tasks\n",
    "> * Datasets, featuring a wide variety of data for different domains and modalities..\n",
    "> * Spaces, interactive apps for demonstrating ML models directly in your browser.\n",
    ">\n",
    "> The Hub offers versioning, commit history, diffs, branches, and over a dozen library integrations! You can learn more about the features that all repositories share in the Repositories documentation.\"\n",
    "\n",
    "We strongly encourage you to read the [Model Hub](https://huggingface.co/docs/hub/models-the-hub) and [Model Card](https://huggingface.co/docs/hub/model-cards) documentation.  The former explains how models are stored and accessed from the hub, while the latter explains how models are documented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf6ab6a",
   "metadata": {},
   "source": [
    "<h3>Pushing to the Hub</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f0934",
   "metadata": {},
   "source": [
    "PyChemAuth provides some simple utilities to get you started saving your models on HF Hub, but only a very basic Card is created with the commands below and you should go to your (newly created) repo and document you model further there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cfe90c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:56:53.287843Z",
     "start_time": "2024-07-10T13:56:53.179894Z"
    },
    "id": "9cfe90c1"
   },
   "outputs": [],
   "source": [
    "# Check out the documentation for more information.\n",
    "?HuggingFace.push_to_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "536339bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:56:57.197987Z",
     "start_time": "2024-07-10T13:56:57.162364Z"
    },
    "id": "536339bf"
   },
   "outputs": [],
   "source": [
    "# To create repos you will need to specify a token which acts as a password behind the scenes.\n",
    "# To do this, go to hugginface.co and Create a token under Settings > Access Tokens.\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    # Colab has a nice way to store these \"secrets\" which you can learn about in this YouTube video:\n",
    "    # https://www.youtube.com/watch?v=LPa51KxqUAw\n",
    "    from google.colab import userdata\n",
    "    TOKEN = userdata.get(\n",
    "        'HF_TOKEN' # CHange this to whatever you save you HF token as in the Secrets menu on Colab\n",
    "    )\n",
    "else:\n",
    "    # Otherwise, you can just paste the token here; but be careful not to share this with anyone.\n",
    "    TOKEN = \"hf_*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac59d4bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:57:04.418460Z",
     "start_time": "2024-07-10T13:57:02.649208Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "ac59d4bc",
    "outputId": "73be9bbb-bf0a-4371-b988-c22338c42b5c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mahynski/pychemauth-sharing-demo/commit/e2390ed8adc8df53fb6a7d27eda3c090aedc4662', commit_message='Pushing model on 2024-07-10 14:17:24.764004', commit_description='', oid='e2390ed8adc8df53fb6a7d27eda3c090aedc4662', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's push the model to the hub.\n",
    "# The first time a model is pushed to a repo that doesn't exist, it is created with a basic Card.\n",
    "# In the future, this will only update the repo and should not overwrite anything you put in the Card.\n",
    "HuggingFace.push_to_hub(\n",
    "    model=model,\n",
    "    namespace=\"mahynski\",\n",
    "    repo_name=\"pychemauth-sharing-demo\", # Create a name for this model\n",
    "    private=False, # The default is True, but since this is a demonstration we will set this to public\n",
    "    token=TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ceea11",
   "metadata": {},
   "source": [
    "Now you can go check the model out at https://huggingface.co/mahynski/pychemauth-sharing-demo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e5e706",
   "metadata": {},
   "source": [
    "<h3>Downloading Pre-trained Models</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85ecabe",
   "metadata": {
    "id": "e85ecabe"
   },
   "source": [
    "Once your model is on the Hub, anyone can download it! This way, you can share models with colleagues easily by just sending them to the correct website. The commands to download a model created by PyChemAuth are given below.\n",
    "\n",
    "**Note: you can also control access to your model by keeping the repo private, or by using [gating](https://huggingface.co/docs/hub/en/models-gated).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f90c07ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:57:07.812475Z",
     "start_time": "2024-07-10T13:57:07.781617Z"
    },
    "id": "f90c07ce"
   },
   "outputs": [],
   "source": [
    "# Check out the documentation for more information.\n",
    "?HuggingFace.from_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2c0e9c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:57:11.332583Z",
     "start_time": "2024-07-10T13:57:11.182042Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "9462cbb6495d4fd9aefbcac8a820eb60",
      "3e9440e146c24de3a2dbc2585c2bbaae",
      "1e280ad804764478a111feabac36f2f0",
      "54993947ad1c4f99a21694edf1102355",
      "9c6b3cc7097a47ce8859e9121d45cfa9",
      "072416045d654aae9950ab427c6978fb",
      "0204f05f85e342baa1465463493fc7af",
      "7b119652d2324842aeee23d124f06f65",
      "c87dde5bf8ad49789cf2e1a5d6aabaa6",
      "1b6da2efce3d455990ad9961117d584c",
      "97968335eece4ec1b54f14ea0b7eed76"
     ]
    },
    "id": "f2c0e9c3",
    "outputId": "b8f3e210-ae2d-4819-a335-bb21afc66381"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9462cbb6495d4fd9aefbcac8a820eb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.pkl:   0%|          | 0.00/3.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "downloaded_model = HuggingFace.from_pretrained(\n",
    "    model_id=\"mahynski/pychemauth-sharing-demo\",\n",
    "    token=None # For public models we don't need a token to access them!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23cc7010",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:57:16.969765Z",
     "start_time": "2024-07-10T13:57:16.918462Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23cc7010",
    "outputId": "e8998eb2-c910-453e-f5cd-50f7851de236"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downloaded_model.predict(X_test_dds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06ce0990",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T13:57:17.889579Z",
     "start_time": "2024-07-10T13:57:17.840199Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06ce0990",
    "outputId": "3aa467ab-610b-481d-e029-4f7f9e4f6522"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'autoscaler': <pychemauth.preprocessing.scaling.CorrectedScaler at 0x7a7bed782200>,\n",
       " 'my_chosen_model': DDSIMCA_Model(n_components=1)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downloaded_model.named_steps"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "oyster-provenance",
   "language": "python",
   "name": "oyster-provenance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0204f05f85e342baa1465463493fc7af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "072416045d654aae9950ab427c6978fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b6da2efce3d455990ad9961117d584c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e280ad804764478a111feabac36f2f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b119652d2324842aeee23d124f06f65",
      "max": 3169,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c87dde5bf8ad49789cf2e1a5d6aabaa6",
      "value": 3169
     }
    },
    "3e9440e146c24de3a2dbc2585c2bbaae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_072416045d654aae9950ab427c6978fb",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0204f05f85e342baa1465463493fc7af",
      "value": "model.pkl: 100%"
     }
    },
    "54993947ad1c4f99a21694edf1102355": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b6da2efce3d455990ad9961117d584c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_97968335eece4ec1b54f14ea0b7eed76",
      "value": " 3.17k/3.17k [00:00&lt;00:00, 155kB/s]"
     }
    },
    "7b119652d2324842aeee23d124f06f65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9462cbb6495d4fd9aefbcac8a820eb60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3e9440e146c24de3a2dbc2585c2bbaae",
       "IPY_MODEL_1e280ad804764478a111feabac36f2f0",
       "IPY_MODEL_54993947ad1c4f99a21694edf1102355"
      ],
      "layout": "IPY_MODEL_9c6b3cc7097a47ce8859e9121d45cfa9"
     }
    },
    "97968335eece4ec1b54f14ea0b7eed76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c6b3cc7097a47ce8859e9121d45cfa9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c87dde5bf8ad49789cf2e1a5d6aabaa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
